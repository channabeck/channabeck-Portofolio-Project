# -*- coding: utf-8 -*-
"""Rock-Paper-Scissors-Image-Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cKyNnK0ZTGAaa-xg5x7LvIYhf1oFizZe

# **Tugas Dicoding Proyek Akhir : Image Classification Model Deployment**

Nama : Moh Channa Beck Sutansyah

No Telepon : +6285728188067

Kota Tempat Tinggal : Kudus

**1. Install Library yang dibutuhkan seperti Tensorflow, Zipfile dan lain-lain**
"""

#Mengimport Library yang dibutuhkan
import tensorflow as tf
import zipfile
import os
import numpy as np
import matplotlib.pyplot as plt
print(tf.__version__)

"""**2. Download Dataset Menggunakan Wget Command dan simpan di direktori temporary (/tmp/rockpaperscissors.zip)**"""

#Mendapatkan dataset melalui wget command
!wget --no-check-certificate \
    https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
     -O /tmp/rockpaperscissors.zip

"""**3.Ekstraksi File Zip Mengunakan Zipfile**"""

# melakukan ekstraksi pada file zip
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/')
zip_ref.close()

"""**4.Install Tree Untuk Memudahkan Melihat Struktur File Secara Keseluruhan**"""

#Menginstall tree
!apt-get install tree

#melihat struktur file dari rockpaperscissors
!tree -d '/tmp'

"""**5. Install Split Folder dan Split Folder Train dan Validation dengan Ratio 80% : 20%**"""

#Install Split_Folder untuk membagi image folder menjadi train dan validation
!pip install split_folders

#Membagi Image menjadi 80% Train dan 20% Validation
import splitfolders
splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', '/tmp/rockpaperscissors/rps-cv-images/base', seed=1, ratio=(.8, .2))

#cek lagi struktur file base
!tree -d '/tmp'

#Menentukan direktori train dan validation
train_dir = '/tmp/rockpaperscissors/rps-cv-images/base/train'
val_dir = '/tmp/rockpaperscissors/rps-cv-images/base/val'

import numpy as np
#Mengecek jumlah data train dan validation
length_train_paper = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/train/paper'))
length_train_rock = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/train/rock'))
length_train_scissors = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/train/scissors'))
length_train = length_train_paper + length_train_rock + length_train_scissors

length_val_paper = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/val/paper'))
length_val_rock = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/val/rock'))
length_val_scissors = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/base/val/scissors'))
length_val = length_val_paper + length_val_rock + length_val_scissors

print('Jumlah Data Train :' + str(length_train))
print('Jumlah Data Validasi :' + str(length_val))

"""**6. Augmentasi Gambar Menggunakan Image Data Generator**"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
 
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=25,
                    horizontal_flip=True,
                    shear_range = 0.3,
                    fill_mode = 'nearest')
 
test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=25,
                    horizontal_flip=True,
                    shear_range = 0.3,
                    fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
        train_dir,  
        target_size=(150, 150),  
        batch_size=32,
        class_mode='categorical')   # karena merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
 
validation_generator = test_datagen.flow_from_directory(
        val_dir, 
        target_size=(150, 150),
        batch_size=32, 
        class_mode='categorical') # karena merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'

"""**7. Membangun Arsitektur CNN**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D
from tensorflow.keras.optimizers import SGD
                               
model =  tf.keras.models.Sequential()

model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(150, 150, 3)))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(256, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.summary()

"""**8. Melakukan Optimasi Menggunakan SGD sebagai Optimizer**"""

model.compile(optimizer = 'Adam',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

BATCH_SIZE = 32
EPOCHS = 50

callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)

# latih model dengan model.fit 
history = model.fit(train_generator,
          steps_per_epoch=BATCH_SIZE,
          epochs=EPOCHS,
          validation_data=validation_generator,
          validation_steps=5,
          verbose=2,callbacks=[callback])

"""**9. Evaluasi Model**"""

nilai = model.evaluate(train_generator)

print('Loss: '+ str(nilai[0]))
print('Accuracy: ' + str(nilai[1]))

nilai = model.evaluate(validation_generator)

print('Loss: '+ str(nilai[0]))
print('Accuracy: ' + str(nilai[1]))

#Memvisualisasikan Akurasi dan Loss dari tiap-tiap Epochs
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(17)
plt.plot(epochs_range, train_accuracy, label='Training Accuracy')
plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')
plt.title('Akurasi Train dan Validation ')
plt.legend()
plt.show()

plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.title('Loss Train dan Validation')
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from keras.preprocessing import image
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for upload_file in uploaded.keys():
 
  # memprediksi gambar
  path = upload_file
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)
  
  print(upload_file)
  if classes[0,0]==1:
    print('Gambar yang diupload adalah')
    print('Paper')
  elif classes[0,1]==1:
    print('Gambar yang diupload adalah')
    print('Rock')
  else:
    print('Gambar yang diupload adalah')
    print('Scissor')

"""**9. Konversi Model Ke TF Lite**"""

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)