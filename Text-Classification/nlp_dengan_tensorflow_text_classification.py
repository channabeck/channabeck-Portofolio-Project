# -*- coding: utf-8 -*-
"""NLP-dengan-TensorFlow-Text-Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JJbrcVXaJMmNdvPDJu2CFCJ-i94_nGfy

# **Tugas Dicoding Proyek Akhir : Klasifikasi Gambar pada  Belajar Machine Learning untuk Pemula**

Nama : Moh Channa Beck Sutansyah

No Telepon : +6285728188067

Kota Tempat Tinggal : Kudus

**1.Download Dataset dari Kaggle**
"""

#Install Kaggle
!pip install -q kaggle

#Upload Json Kaggle
from google.colab import files
files.upload()

!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

#Download Dataset dari Kaggle
!kaggle datasets download -d team-ai/spam-text-message-classification

#Unzip File
!mkdir spam-text-message-classification
!unzip spam-text-message-classification.zip -d spam-text-message-classification
!ls spam-text-message-classification

"""**2. Import Library**"""

#import library 
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.callbacks import EarlyStopping

"""**3.Read Dataset**"""

#Read Dataset
data = pd.read_csv("spam-text-message-classification/SPAM text message 20170820 - Data.csv")
data

"""**4. Label Encoding**"""

#Label Encoding
le = LabelEncoder()
x = data['Message'].values
y = data['Category'].values
y = le.fit_transform(y)
y = y.reshape(-1,1)

"""**5. Pembagian Dataset Menjadi 80% Data Train dan 20% Data Validation**"""

#Pembagian Data menjadi Data Train dan  Data Validation dengan rasio 0.8 : 0.2
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

"""**6. Membangun model sequential dengan lstm dan embedding**"""

#membangun model sequential dengan lstm dan embedding
model = tf.keras.Sequential([
    tf.keras.layers.Embedding (1000,50,input_length = 150),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

"""**7.Membuat Fungsi Tokenizer**"""

#membuat fungsi tokenizer
tokenizer = Tokenizer(num_words=1000, oov_token='x')
tokenizer.fit_on_texts(x_train) 
tokenizer.fit_on_texts(x_test)
 
sekuens_latih = tokenizer.texts_to_sequences(x_train)
sekuens_test = tokenizer.texts_to_sequences(x_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

"""**7.Menggunakan Callback EarlyStopping**

Source : https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
"""

callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)

"""**8. Melatih Model**"""

# latih model dengan model.fit
num_epochs = 20
history = model.fit(padded_latih, y_train, epochs=num_epochs, 
                    validation_data=(padded_test, y_test), verbose=2,callbacks=[callback])

"""**9.Plot Loss dan Akurasi**"""

#Memvisualisasikan Akurasi dan Loss dari tiap-tiap Epochs
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(14)
plt.plot(epochs_range, train_accuracy, label='Training Accuracy')
plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')
plt.title('Akurasi Train dan Validation ')
plt.legend()
plt.show()

plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.title('Loss Train dan Validation')
plt.legend()
plt.show()

