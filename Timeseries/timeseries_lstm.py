# -*- coding: utf-8 -*-
"""Timeseries-LSTM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TB8cYiE0NR1yeJZ2DlREC9gAac8EKpHO

# **Tugas Dicoding Proyek Akhir : Time Series dengan LSTM**

Nama : Moh Channa Beck Sutansyah

No Telepon : +6285728188067

Kota Tempat Tinggal : Kudus

**1.Download Dataset dari Kaggle**
"""

#Install Kaggle
!pip install -q kaggle

#Upload Json Kaggle
from google.colab import files
files.upload()

!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

#Download Dataset dari Kaggle
!kaggle datasets download -d team-ai/bitcoin-price-prediction

"""**2. Unzip File**"""

#Unzip File
!mkdir bitcoin-price-prediction
!unzip bitcoin-price-prediction.zip -d bitcoin-price-prediction
!ls bitcoin-price-prediction

"""**3. Import Library**"""

import numpy as np
import pandas as pd
import tensorflow as tf
from keras.layers.core import Dense, Activation
from keras.layers.recurrent import LSTM
from keras.preprocessing.sequence import TimeseriesGenerator
from keras.models import Sequential
from sklearn.model_selection import  train_test_split
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

"""**4. Read Dataset**"""

df = pd.read_csv('bitcoin-price-prediction/bitcoin_price_Training - Training.csv')

df

df['Date'] = pd.to_datetime(df.Date)
df = df.sort_values(by=['Date'])

"""**Mengecek Date(Timestamp) apakah memiliki data harian non-holiday lengkap?**"""

from pandas.tseries.holiday import USFederalHolidayCalendar as calendar

dr = pd.date_range(start='2013-04-28', end='2017-07-31')
df_h = pd.DataFrame()
df_h['Date'] = dr

cal = calendar()
holidays = cal.holidays(start=dr.min(), end=dr.max())

df_h['Holiday'] = df_h['Date'].isin(holidays)
df_h

"""Disini terlihat bahwa jumlah baris yang pada dataset bitcoin (dataset yang dipakai) sama dengan jumlah hari (non-holiday+holiday) kalendar yaitu 1556 baris.

Perlu diketahui juga bitcoin tidak memiliki hari libur trading, jadi data ini sudah lengkap dan ordered

**5. Cek Null, Set Index dan Drop Column yang tidak perlu**
"""

df.isnull().sum()

"""Disini Dataset tidak memiliki missing value """

df = df.set_index('Date')

df.head()

df = df.drop(['Open'], axis = 1)
df = df.drop(['High'], axis = 1)
df = df.drop(['Volume'], axis = 1)
df = df.drop(['Low'], axis = 1)
df = df.drop(['Market Cap'], axis = 1)

df

"""**Membagi Train dan Validation Data (80% : 20%)**"""

test_size = 0.20
data_train, data_val = train_test_split(df.values, test_size=test_size, shuffle=False)

scaler = MinMaxScaler()
data_train = scaler.fit_transform(data_train.reshape(-1, 1))
data_val = scaler.fit_transform(data_val.reshape(-1, 1))

split=int((1-test_size)*len(df))

date_train = df.index[:split]
date_test = df.index[split:]

look_back = 20
data_train = tf.keras.preprocessing.sequence.TimeseriesGenerator(data_train, data_train, length=look_back, batch_size=20)     
data_val = tf.keras.preprocessing.sequence.TimeseriesGenerator(data_val, data_val, length=look_back, batch_size=1)

"""Menggunakan Model Sequential + LSTM"""

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True, input_shape=(look_back, 1)),
  tf.keras.layers.LSTM(60),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

model.summary()

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=["mae"])
history = model.fit_generator(data_train, validation_data=(data_val), epochs=100, verbose=2)

#Memvisualisasikan Akurasi dan Loss dari tiap-tiap Epochs
train_mae = history.history['mae']
val_mae = history.history['val_mae']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(100)
plt.plot(epochs_range, train_mae, label='Training Mae')
plt.plot(epochs_range, val_mae, label='Validation Mae')
plt.title('Mae Train dan Validation ')
plt.legend()
plt.show()

plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.title('Loss Train dan Validation')
plt.legend()
plt.show()

callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=["mae"])
history = model.fit_generator(data_train, validation_data=(data_val), epochs=100, verbose=2,callbacks=[callback])

#Memvisualisasikan Akurasi dan Loss dari tiap-tiap Epochs
train_mae = history.history['mae']
val_mae = history.history['val_mae']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(100)
plt.plot(epochs_range, train_mae, label='Training Mae')
plt.plot(epochs_range, val_mae, label='Validation Mae')
plt.title('Mae Train dan Validation ')
plt.legend()
plt.show()

plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.title('Loss Train dan Validation')
plt.legend()
plt.show()

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=["mae"])
history = model.fit_generator(data_train, validation_data=(data_val), epochs=100, verbose=2,callbacks=[callback])

#Memvisualisasikan Akurasi dan Loss dari tiap-tiap Epochs
train_mae = history.history['mae']
val_mae = history.history['val_mae']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(100)
plt.plot(epochs_range, train_mae, label='Training Mae')
plt.plot(epochs_range, val_mae, label='Validation Mae')
plt.title('Mae Train dan Validation ')
plt.legend()
plt.show()

plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.title('Loss Train dan Validation')
plt.legend()
plt.show()

"""**Summary Checklist**

1.Dataset memiliki minimal memiliki 1000 sampel
"""

df.count()

"""2. Harus menggunakan LSTM dalam arsitektur model

"""

#model = tf.keras.models.Sequential([
  #tf.keras.layers.LSTM(60, return_sequences=True, input_shape=(look_back, 1)),
  #tf.keras.layers.LSTM(60),
  #tf.keras.layers.Dense(30, activation="relu"),
  #tf.keras.layers.Dense(10, activation="relu"),
  #tf.keras.layers.Dense(1),
#])

"""3. Validation set sebesar 20% dari total dataset """

print('jumlah data train: ' +str(len(data_train)))
print('jumlah data validation: ' +str(len(data_val)))
print('rasio data validation: ' +str(len(data_val)/len(df)))

"""4. Model harus menggunakan model sequential. """

#model = tf.keras.models.Sequential([
  #tf.keras.layers.LSTM(60, return_sequences=True, input_shape=(look_back, 1)),
  #tf.keras.layers.LSTM(60),
  #tf.keras.layers.Dense(30, activation="relu"),
  #tf.keras.layers.Dense(10, activation="relu"),
  #tf.keras.layers.Dense(1),
#]

"""5. Harus menggunakan Learning Rate pada Optimizer. """

#optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)

"""6.MAE < 10% skala data."""

print('Mae Train Terakhir: '+ str(history.history['mae'][99]))
print('Mae Validation Terakhir: '+ str(history.history['val_mae'][99]))

df.describe()

mae = float(history.history['mae'][99])
mae_val = float(history.history['val_mae'][99])
mae_scale = round((df['Close'].max() - df['Close'].min()) * (10 / 100), 2)
if mae < mae_scale:
  print('mae train lebih kecil dari mae_scale 10% (terpenuhi)')
else:
  print('mae train lebih besar dari mae_scale(tidak terpenuhi)')
if mae_val < mae_scale:
  print('mae validation lebih kecil dari mae_scale 10% (terpenuhi)')
else:
  print('mae train lebih besar dari mae_scale(tidak terpenuhi)')